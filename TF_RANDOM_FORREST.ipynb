{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import glob\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_LOC = '/nvme/UCIAccData/'\n",
    "activity_list = [i for i in glob.glob(f'{IMAGE_LOC}/*') if i.find('_') > 0 and \"MODEL\" not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(activity_list):\n",
    "    '''Read files in each activity in activity_list\n",
    "    Returns dict: key = activity name -> array of numpy arrays of shape (n_observations, 3) = (ax,ay,az)\n",
    "    '''\n",
    "    data = {}\n",
    "    \n",
    "    for t in activity_list: #loop over each activity type\n",
    "        activity_name = t.split('/')[-1]\n",
    "        data[activity_name] = []\n",
    "    \n",
    "        filenames = glob.glob(t + '/*')\n",
    "        \n",
    "        for f in filenames: #loop over every participants time-series\n",
    "            df = pd.read_csv(f, sep=' ', header=None)\n",
    "            \n",
    "            #ts = np.sqrt((df**2).sum(axis=1)) #magnitude of acceleration vector\n",
    "            \n",
    "            data[activity_name].append(np.array(df))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_acceleration_timeseries(data):\n",
    "    '''Input: data returned by read_data\n",
    "    Output: dictionary mapping activity name -> list of single time-series of acceleration magnitudes\n",
    "    '''\n",
    "    \n",
    "    data_ts = {}\n",
    "    \n",
    "    for k in data:\n",
    "        data_ts[k] = []\n",
    "        \n",
    "        for sample in data[k]: #(ax, ay, az)\n",
    "            data_ts[k].append(np.sqrt((sample**2).sum(axis=1)))\n",
    "    \n",
    "    return data_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ts = read_data(activity_list)\n",
    "data_ts = get_acceleration_timeseries(data_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_stats(ts, bins):\n",
    "    #basic statistical measures\n",
    "    mean = np.mean(ts)\n",
    "    median = np.median(ts)\n",
    "    std = np.std(ts)\n",
    "    length = len(ts)\n",
    "    kurtosis = scipy.stats.kurtosis(ts)\n",
    "    \n",
    "    n,b,p = plt.hist(ts, bins=bins)\n",
    "    n = np.array(n)/float(np.sum(n)) #normalize i.e. fraction of entries in each bin\n",
    "    \n",
    "    if median == 0: \n",
    "        features = {'mean_over_median': 0, #dimensionless            \n",
    "                    'std_over_median': 0, #dimensionless            \n",
    "                    'length': length,\n",
    "                    'kurtosis': kurtosis, #already dimensionless by definition\n",
    "                   }\n",
    "        \n",
    "    else: \n",
    "        features = {'mean_over_median': mean/median, #dimensionless            \n",
    "            'std_over_median': std/median, #dimensionless            \n",
    "            'length': length,\n",
    "            'kurtosis': kurtosis, #already dimensionless by definition\n",
    "           }\n",
    "        \n",
    "    for i, val in enumerate(n):\n",
    "        features[f'binfrac_{i}'] = val\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFAVJREFUeJzt3X+sX/V93/HnqziUllJsgmdR25nZYiWhk/ixOyBKgzpYjSFRjNSUkWXDRZ68SWxLpkatqSaRQpCINpUk2orkgVsTZSEeSYqVsjDLoWv7BwQTMhpwEC4Jwxbg29gQGpZkpO/98f04XKhv7/fa19/j+PN8SFffc97n8z3f9zk6vi+f8z3f701VIUnqz08N3YAkaRgGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTi4Zu4G9z5pln1qpVq4ZuQ5J+ojzyyCN/WVVL5xp3XAfAqlWr2LVr19BtSNJPlCTPjDPOS0CS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSp4/qTwJL6sWrTHw3dAgDfvvU9Q7cwMZ4BSFKnDABJ6tScAZDkbUm+PuPnu0k+nOSMJDuSPNUel7TxSfKpJHuSPJbkghnrWt/GP5Vk/bHcMEnS327OAKiqJ6vqvKo6D/iHwCvAF4FNwM6qWg3sbPMAVwCr289G4HaAJGcANwIXARcCNx4KDUnS5M33EtBlwF9U1TPAOmBrq28FrmrT64C7auRBYHGSs4DLgR1VdaCqDgI7gLVHvQWSpCMy3wC4Bvhsm15WVc+16eeBZW16OfDsjOfsbbXZ6q+TZGOSXUl2TU9Pz7M9SdK4xg6AJCcD7wP++xuXVVUBtRANVdXmqpqqqqmlS+f8gzaSpCM0nzOAK4CvVdULbf6FdmmH9ri/1fcBK2c8b0WrzVaXJA1gPgHwAV67/AOwHTh0J8964N4Z9Wvb3UAXAy+1S0X3A2uSLGlv/q5pNUnSAMb6JHCSU4FfAf7VjPKtwLYkG4BngKtb/T7gSmAPozuGrgOoqgNJbgYebuNuqqoDR70FkqQjMlYAVNX3gDe/ofYdRncFvXFsAdfPsp4twJb5tylJWmh+EliSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnq1FgBkGRxknuSfDPJ7iTvTHJGkh1JnmqPS9rYJPlUkj1JHktywYz1rG/jn0qy/lhtlCRpbuOeAXwS+HJVvR04F9gNbAJ2VtVqYGebB7gCWN1+NgK3AyQ5A7gRuAi4ELjxUGhIkiZvzgBIcjpwCXAnQFX9sKpeBNYBW9uwrcBVbXodcFeNPAgsTnIWcDmwo6oOVNVBYAewdkG3RpI0tnHOAM4GpoHfT/JokjuSnAosq6rn2pjngWVtejnw7Izn72212eqSpAGMEwCLgAuA26vqfOB7vHa5B4CqKqAWoqEkG5PsSrJrenp6IVYpSTqMcQJgL7C3qh5q8/cwCoQX2qUd2uP+tnwfsHLG81e02mz116mqzVU1VVVTS5cunc+2SJLmYc4AqKrngWeTvK2VLgOeALYDh+7kWQ/c26a3A9e2u4EuBl5ql4ruB9YkWdLe/F3TapKkASwac9y/BT6T5GTgaeA6RuGxLckG4Bng6jb2PuBKYA/wShtLVR1IcjPwcBt3U1UdWJCtkCTN21gBUFVfB6YOs+iyw4wt4PpZ1rMF2DKfBiVJx4afBJakThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqfG+qPwSb4NvAz8CHi1qqaSnAF8DlgFfBu4uqoOJgnwSeBK4BXg16vqa20964H/0Fb7saraunCbIukn2Wnv2DR0C817hm5gYuZzBvCPq+q8qppq85uAnVW1GtjZ5gGuAFa3n43A7QAtMG4ELgIuBG5MsuToN0GSdCSO5hLQOuDQ/+C3AlfNqN9VIw8Ci5OcBVwO7KiqA1V1ENgBrD2K15ckHYVxA6CA/5nkkSQbW21ZVT3Xpp8HlrXp5cCzM567t9Vmq0uSBjDWewDAL1XVviR/B9iR5JszF1ZVJamFaKgFzEaAt7zlLQuxSknSYYx1BlBV+9rjfuCLjK7hv9Au7dAe97fh+4CVM56+otVmq7/xtTZX1VRVTS1dunR+WyNJGtucAZDk1CSnHZoG1gDfALYD69uw9cC9bXo7cG1GLgZeapeK7gfWJFnS3vxd02qSpAGMcwloGfDF0d2dLAL+W1V9OcnDwLYkG4BngKvb+PsY3QK6h9FtoNcBVNWBJDcDD7dxN1XVgQXbEknSvMwZAFX1NHDuYerfAS47TL2A62dZ1xZgy/zblCQtND8JLEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTo0dAElOSvJoki+1+bOTPJRkT5LPJTm51X+6ze9py1fNWMcNrf5kkssXemMkSeObzxnAh4DdM+Y/DtxWVW8FDgIbWn0DcLDVb2vjSHIOcA3wi8Ba4PeSnHR07UuSjtRYAZBkBfAe4I42H+BS4J42ZCtwVZte1+Zpyy9r49cBd1fVD6rqW8Ae4MKF2AhJ0vyNewbwCeA3gb9u828GXqyqV9v8XmB5m14OPAvQlr/Uxv+4fpjn/FiSjUl2Jdk1PT09j02RJM3HnAGQ5L3A/qp6ZAL9UFWbq2qqqqaWLl06iZeUpC4tGmPMu4D3JbkSOAX4eeCTwOIki9r/8lcA+9r4fcBKYG+SRcDpwHdm1A+Z+RxJ0oTNeQZQVTdU1YqqWsXoTdyvVNUHgQeA97dh64F72/T2Nk9b/pWqqla/pt0ldDawGvjqgm2JJGlexjkDmM1vAXcn+RjwKHBnq98JfDrJHuAAo9Cgqh5Psg14AngVuL6qfnQUry9JOgrzCoCq+mPgj9v00xzmLp6q+j7wa7M8/xbglvk2KUlaeH4SWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUnAGQ5JQkX03yv5M8nuR3Wv3sJA8l2ZPkc0lObvWfbvN72vJVM9Z1Q6s/meTyY7VRkqS5jXMG8APg0qo6FzgPWJvkYuDjwG1V9VbgILChjd8AHGz129o4kpwDXAP8IrAW+L0kJy3kxkiSxjdnANTIX7XZN7WfAi4F7mn1rcBVbXpdm6ctvyxJWv3uqvpBVX0L2ANcuCBbIUmat7HeA0hyUpKvA/uBHcBfAC9W1attyF5geZteDjwL0Ja/BLx5Zv0wz5EkTdhYAVBVP6qq84AVjP7X/vZj1VCSjUl2Jdk1PT19rF5Gkro3r7uAqupF4AHgncDiJIvaohXAvja9D1gJ0JafDnxnZv0wz5n5GpuraqqqppYuXTqf9iRJ8zDOXUBLkyxu0z8D/Aqwm1EQvL8NWw/c26a3t3na8q9UVbX6Ne0uobOB1cBXF2pDJEnzs2juIZwFbG137PwUsK2qvpTkCeDuJB8DHgXubOPvBD6dZA9wgNGdP1TV40m2AU8ArwLXV9WPFnZzJEnjmjMAquox4PzD1J/mMHfxVNX3gV+bZV23ALfMv01J0kLzk8CS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1apw/CCNJx9yvfutXh26hO54BSFKnDABJ6pQBIEmdMgAkqVNzBkCSlUkeSPJEkseTfKjVz0iyI8lT7XFJqyfJp5LsSfJYkgtmrGt9G/9UkvXHbrMkSXMZ5wzgVeA3quoc4GLg+iTnAJuAnVW1GtjZ5gGuAFa3n43A7TAKDOBG4CLgQuDGQ6EhSZq8OQOgqp6rqq+16ZeB3cByYB2wtQ3bClzVptcBd9XIg8DiJGcBlwM7qupAVR0EdgBrF3RrJEljm9d7AElWAecDDwHLquq5tuh5YFmbXg48O+Npe1tttrokaQBjB0CSnwM+D3y4qr47c1lVFVAL0VCSjUl2Jdk1PT29EKuUJB3GWAGQ5E2Mfvl/pqq+0MovtEs7tMf9rb4PWDnj6Stabbb661TV5qqaqqqppUuXzmdbJEnzMM5dQAHuBHZX1e/OWLQdOHQnz3rg3hn1a9vdQBcDL7VLRfcDa5IsaW/+rmk1SdIAxvkuoHcB/wL48yRfb7XfBm4FtiXZADwDXN2W3QdcCewBXgGuA6iqA0luBh5u426qqgMLshWSpHmbMwCq6s+AzLL4ssOML+D6Wda1BdgynwYlSceGnwSWpE4ZAJLUKQNAkjplAEhSp/yLYFLn9m7606FbGDll6Ab64xmAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pS3gUoDWrXpj4ZugT/j54duQQPxDECSOmUASFKnDABJ6pQBIEmd8k1gSceFd1/y6aFbaD46dAMT4xmAJHXKAJCkThkAktSpOQMgyZYk+5N8Y0btjCQ7kjzVHpe0epJ8KsmeJI8luWDGc9a38U8lWX9sNkeSNK5x3gT+A+A/A3fNqG0CdlbVrUk2tfnfAq4AVrefi4DbgYuSnAHcCEwBBTySZHtVHVyoDZF0ZO44ZefQLQDw7qEb6NCcZwBV9SfAgTeU1wFb2/RW4KoZ9btq5EFgcZKzgMuBHVV1oP3S3wGsXYgNkCQdmSN9D2BZVT3Xpp8HlrXp5cCzM8btbbXZ6n9Dko1JdiXZNT09fYTtSZLmctSfA6iqSlIL0Uxb32ZgM8DU1NSCrVfS8e2b2/7r0C0AcNmlQ3cwOUd6BvBCu7RDe9zf6vuAlTPGrWi12eqSpIEcaQBsBw7dybMeuHdG/dp2N9DFwEvtUtH9wJokS9odQ2taTZI0kDkvASX5LPDLwJlJ9jK6m+dWYFuSDcAzwNVt+H3AlcAe4BXgOoCqOpDkZuDhNu6mqnrjG8uSOvYfF//foVsA4PqhG5igOQOgqj4wy6LLDjO2mGX/VdUWYMu8upMkHTN+GZw0oP/xhx8ZugWuvuE4+TWw+x8N3UF3/CoISeqUASBJnTIAJKlTBoAkdcoAkKROHSdv/0vq3fFwRxQAp/yzoTsY+ehLx/wlPAOQpE55BiAN6L5z//7QLTD6ML96ZABIA3r5HVNDt4AB0C8vAUlSpzwDkDr3iZWvDN0CAKdd9QdDt9C8d+gGJsYAkDr3wXx+6BYA2MXLQ7fQHQNAGtDS5y8ZugX+9f/6w6FbaP7GFwzrGDMA1KePnj50BwCsW/yloVvgjqEbaO44ZefQLQDw0aEbmCADQF3affcvDN0CAKddNXQHx493X/LpoVsY+ZOhG5gcA0Dq3HHzi1cT522gktQpA0CSOjXxS0BJ1gKfBE4C7qiqWyfdg4az++3vGLoFAE67avPQLeg4tff7w78xD7BiAq8x0TOAJCcB/wW4AjgH+ECScybZgyRpZNJnABcCe6rqaYAkdwPrgCcm3IckHdbxczvqu4/5a0w6AJYDz86Y3wtcNOEeNCAvvbzek2t+fegW9Aan7d41dAsTc9zdBppkI7Cxzf5VkiePYnVnAn959F2dENwXr3d87I+PD90AcLzsi+PG08fF/vjIthzN0//uOIMmHQD7gJUz5le02o9V1WZgQf6bmGRXVR0P37c7OPfF67k/XuO+eL2e9sekbwN9GFid5OwkJwPXANsn3IMkiQmfAVTVq0n+DXA/o9tAt1TV45PsQZI0MvH3AKrqPuC+Cb2c7zi+xn3xeu6P17gvXq+b/ZGqGroHSdIA/CoISerUCRkASdYmeTLJniSbhu5n0pKsTPJAkieSPJ7kQ61+RpIdSZ5qj0uG7nVSkpyU5NEkX2rzZyd5qB0jn2s3JXQhyeIk9yT5ZpLdSd7Z67GR5N+3fyPfSPLZJKf0dGyccAHg100A8CrwG1V1DnAxcH3bB5uAnVW1GtjZ5nvxIWD3jPmPA7dV1VuBg8CGQboaxieBL1fV24FzGe2X7o6NJMuBfwdMVdU/YHRjyjV0dGyccAHAjK+bqKofAoe+bqIbVfVcVX2tTb/M6B/4ckb7YWsbthXo4s+RJFkBvIf2x6+SBLgUuKcN6WlfnA5cAtwJUFU/rKoX6fTYYHQjzM8kWQT8LPAcHR0bJ2IAHO7rJpYP1MvgkqwCzgceApZV1XNt0fPAsoHamrRPAL8J/HWbfzPwYlW92uZ7OkbOBqaB32+XxO5IciodHhtVtQ/4T8D/YfSL/yXgETo6Nk7EAFCT5OeAzwMfrqrvzlxWo9u/TvhbwJK8F9hfVY8M3ctxYhFwAXB7VZ0PfI83XO7p6NhYwujM52zgF4BTgbWDNjVhJ2IAzPl1Ez1I8iZGv/w/U1VfaOUXkpzVlp8F7B+qvwl6F/C+JN9mdDnwUkbXwBe3037o6xjZC+ytqofa/D2MAqHHY+OfAN+qqumq+n/AFxgdL90cGydiAHT/dRPtGvedwO6q+t0Zi7YD69v0euDeSfc2aVV1Q1WtqKpVjI6Fr1TVB4EHgPe3YV3sC4Cqeh54NsnbWukyRl/H3t2xwejSz8VJfrb9mzm0L7o5Nk7ID4IluZLRdd9DXzdxy8AtTVSSXwL+FPhzXrvu/duM3gfYBrwFeAa4uqoODNLkAJL8MvCRqnpvkr/H6IzgDOBR4J9X1Q+G7G9SkpzH6A3xk4GngesY/Wewu2Mjye8A/5TRnXOPAv+S0TX/Lo6NEzIAJElzOxEvAUmSxmAASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqf8P0vqy1HdAHzQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(0,100,10)\n",
    "\n",
    "df = []\n",
    "labels = []\n",
    "\n",
    "for k in data_ts: #slow, should parallelize\n",
    "    for elem in data_ts[k]:\n",
    "        df.append(featurize_stats(elem, bins))\n",
    "        labels.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 14)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjay/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_df['label'])\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_df['label'])\n",
    "label_encoder = LabelEncoder()\n",
    "test_labels = label_encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('label', axis=1)\n",
    "X_test = test_df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/sanjay/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/sanjay/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/sanjay/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/lib64/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/lib64/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.9.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e187a1672a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/sanjay/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/sanjay/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/sanjay/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/lib64/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/lib64/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import resources\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params \n",
    "\n",
    "num_steps = 1000 # training steps\n",
    "batch_size = 100 # number of sampels per batch\n",
    "num_classes = 14 # number of classes to categorize \n",
    "num_features = 13 # size of the input data\n",
    "num_trees = 81 # number of trees in our forest\n",
    "max_nodes = 400 # maximum number of nodes (per tree ?)\n",
    "\n",
    "#Data\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,num_features])\n",
    "# For random forest, labels must be integers (the class id)\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "# Random Forest Parameters\n",
    "\n",
    "hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                     num_features=num_features,\n",
    "                                     num_trees=num_trees,\n",
    "                                     max_nodes=max_nodes).fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'num_trees': 81, 'max_nodes': 400, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 10, 'max_fertile_nodes': 0, 'split_after_samples': 250, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'model_name': 'all_dense', 'split_finish_name': 'basic', 'split_pruning_name': 'none', 'collate_examples': False, 'checkpoint_stats': False, 'use_running_stats_method': False, 'initialize_average_splits': False, 'inference_tree_paths': False, 'param_file': None, 'split_name': 'less_or_equal', 'early_finish_check_every_samples': 0, 'prune_every_samples': 0, 'num_classes': 14, 'num_features': 13, 'bagged_num_features': 13, 'bagged_features': None, 'regression': False, 'num_outputs': 1, 'num_output_columns': 15, 'base_random_seed': 0, 'leaf_model_type': 0, 'stats_model_type': 0, 'finish_type': 0, 'pruning_type': 0, 'split_type': 0}\n"
     ]
    }
   ],
   "source": [
    "forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "\n",
    "# Get training graph and loss\n",
    "train_op = forest_graph.training_graph(X,y)\n",
    "loss_op = forest_graph.training_loss(X,y)\n",
    "\n",
    "# Measure Accuracy\n",
    "infer_op, _, _ = forest_graph.inference_graph(X)\n",
    "correct_prediction = tf.equal(tf.argmax(infer_op,1), tf.cast(y, tf.int64))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "#Initilize variables\n",
    "init_vars = tf.group(tf.global_variables_initializer(),\n",
    "                     resources.initialize_resources(resources.shared_resources()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Step 1, Loss: -1.000000, ACC: 0.434022\n",
      "Step 50, Loss: -156.135803, ACC: 0.896661\n",
      "Step 100, Loss: -285.765442, ACC: 0.980922\n",
      "Step 150, Loss: -379.098755, ACC: 1.000000\n",
      "Step 200, Loss: -400.925934, ACC: 1.000000\n",
      "Step 250, Loss: -401.000000, ACC: 1.000000\n",
      "Step 300, Loss: -401.000000, ACC: 1.000000\n",
      "Step 350, Loss: -401.000000, ACC: 1.000000\n",
      "Step 400, Loss: -401.000000, ACC: 1.000000\n",
      "Step 450, Loss: -401.000000, ACC: 1.000000\n",
      "Step 500, Loss: -401.000000, ACC: 1.000000\n",
      "Step 550, Loss: -401.000000, ACC: 1.000000\n",
      "Step 600, Loss: -401.000000, ACC: 1.000000\n",
      "Step 650, Loss: -401.000000, ACC: 1.000000\n",
      "Step 700, Loss: -401.000000, ACC: 1.000000\n",
      "Step 750, Loss: -401.000000, ACC: 1.000000\n",
      "Step 800, Loss: -401.000000, ACC: 1.000000\n",
      "Step 850, Loss: -401.000000, ACC: 1.000000\n",
      "Step 900, Loss: -401.000000, ACC: 1.000000\n",
      "Step 950, Loss: -401.000000, ACC: 1.000000\n",
      "Step 1000, Loss: -401.000000, ACC: 1.000000\n",
      "Test Accuracy: 0.37142858\n"
     ]
    }
   ],
   "source": [
    "# Start session\n",
    "sess = tf.train.MonitoredSession()\n",
    "\n",
    "# Run initializer\n",
    "sess. run(init_vars)\n",
    "\n",
    "# Train\n",
    "for i in range(1, num_steps + 1):\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict={X: X_train, y: train_labels})\n",
    "    \n",
    "    if i % 50 == 0 or i == 1:\n",
    "        acc = sess.run(accuracy_op,feed_dict={X: X_train, y: train_labels})\n",
    "        print('Step %i, Loss: %f, ACC: %f' % (i, l, acc))\n",
    "        \n",
    "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={X: X_test, y: test_labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
